lenses.box=true
lenses.jmx.port=9586
lenses.sql.state.dir="/data/lsql-state-dir"
lenses.port=9991
lenses.secret.file="/var/run/lenses/security.conf"
lenses.storage.directory="/data/lenses"

######################################
# Lenses 5.5 Sample Configuration File
######################################

# Settings that are commented out will use the default value. They are not
# required to be set explicitly.

###

## The mandatory options for Lenses to start are:
## - lenses.secret.file

## The options that may be important to provide a good Lenses experience, are:
## - lenses.sql.state.dir

###

#############################
# Listener and Basic Settings
#############################

## Set the ip:port for Lenses to bind to and optionally a JMX port

#lenses.ip = 0.0.0.0
#lenses.port = 9991
#lenses.jmx.port =
# You can set the root path if you want to run Lenses under a subpath
#lenses.root.path = ""

## Security configuration is managed in an external file

lenses.secret.file = "security.conf"

## Optional settings for serving the web interface over TLS (SSL)
#lenses.ssl.keystore.location = # "/path/to/keystore.jks"
#lenses.ssl.keystore.password = # "changeit"
#lenses.ssl.key.password      = # "changeit"

## Optional directory for temp files. If write access is denied, Lenses falls back to /tmp
#lenses.workspace = "/run"

#####################################
# External Services
#####################################

# Grafana

## If you've setup the Lenses Monitoring Suite, you can set the Grafana address here
## so you get a link to it from inside Lenses UI.

#lenses.grafana = "" # "http://grafana-host:port"


#############################
# Lenses Streaming SQL Engine
#############################

## Lenses SQL Execution Modes set where your Streaming SQL queries will run.  In
## the default setting `IN_PROC`, queries run inside Lenses. Whilst a great way
## to try Streaming SQL, it doesn't scale as well, with the bottleneck being
## network and/or CPU of the single server that runs Lenses. `KUBERNETES` will
## run the queries in your kubernetes cluster.

#lenses.sql.execution.mode = "IN_PROC" # "IN_PROC" or "KUBERNETES"

## Lenses SQL processing engine needs a temporary directory to store
## scratch files. It's important that Lenses (when you run `IN_PROC`)
## or Connect (when you run in `CONNECT`) can write to the path below.
## It can be absolute or relative.

lenses.sql.state.dir = "logs/lenses-sql-kstream-state"

## When in `KUBERNETES` mode, the kube config file and the service account to
## use, should be set. If you are running Lenses itself inside Kubernetes, you
## don't have to adjust these, as we get them via our pod's service account and
## the Kubernetes API.

# lenses.kubernetes.config.file = "/home/lenses/.kube/config"
# lenses.kubernetes.service.account = "default"


###################
# Advanced Settings
###################

###

## It's advised to change the settings below only after you succesfully deployed
## Lenses. Depending on your cluster size and usage, a few tweaks may be needed.
## Feel free to https://launchpass.com/lensesio or contact support if you need
## help.

###

# Information for connector plugins that Lenses do not know about by default

# lenses.connectors.info = [
#       {
#         class.name = "io.tabular.iceberg.connect.IcebergSinkConnector"
#         name = "File Source"
#         instance = "file"
#         sink = true
#         extractor.class = "io.lenses.config.kafka.connect.SimpleTopicsExtractor"
#         icon = "file.png"
#         description = "A connector to source lines from a file into a Kafka topic"
#         author = "Apache Kafka"
#       },
#       ...
#   ]
#   Copy
connectors.info = [
{
    class.name = "io.tabular.iceberg.connect.IcebergSinkConnector"
    name = "Iceberg Sink Connector"
    instance = "file"
    sink = true
    extractor.class = "io.lenses.config.kafka.connect.SimpleTopicsExtractor"
    icon = "iceberg.png"
    description = "Used to sink data to Iceberg tables"
    author = "Tabular"
}]


# Lenses State Topics

## These topics are used to store state. They are created on startup if they do
## not exist.

#lenses.topics.external.topology = "__topology"
#lenses.topics.replication.external.topology = 1
#lenses.topics.external.metrics = "__topology__metrics"
#lenses.topics.replication.external.metrics = 1


# Lenses SQL

## Set up Lenses SQL

#lenses.sql.max.bytes = 20971520
#lenses.sql.max.time = 3600000
#lenses.sql.sample.default = 2 # Sample 2 messages every 200 msec
#lenses.sql.sample.window = 200

#lenses.sql.monitor.frequency = 10000

## When in `KUBERNETES` mode you can tweak the LSQL kubernetes images and pods.

# Data Application Deployment (DAD)
# lenses.deployments.events.buffer.size=10000
# lenses.deployments.errors.buffer.size=1000

# Kubernetes configuration. Contact us at sales@lenses.io
# lenses.kubernetes.processor.image.name = "lensesioextra/sql-processor"
# lenses.kubernetes.processor.image.tag = "5.5"
# lenses.kubernetes.pull.policy = "Always"
# lenses.kubernetes.watch.reconnect.limit = 10
# lenses.kubernetes.pod.mem.limit = "1152M"
# lenses.kubernetes.pod.mem.request = "128M"
# lenses.kubernetes.pod.heap = "900M"
# Filling this configuration will limit the available namespaces to use inside Lenses.io
# lenses.kubernetes.namespaces = {
#     clusterName1 = ["namespace11", "namespace12"]
#     clusterName2 = ["namespace21", "namespace22"]
# }

# Lenses

## Set up Lenses workers

#lenses.metrics.workers = 16
#lenses.offset.workers = 5

## Lenses internal refresh (in msec)

#lenses.interval.summary = 10000
#lenses.interval.consumers = 10000
#lenses.interval.partitions.messages = 10000
#lenses.interval.type.detection = 30000
#lenses.interval.user.session.ms = 14400000
#lenses.interval.user.session.refresh = 60000
#lenses.interval.schema.registry.healthcheck = 30000
#lenses.interval.topology.topics.metrics = 10000
#lenses.interval.processor.metrics.buffer.ms = 10000
#lenses.interval.alert.manager.healthcheck = 5000
#lenses.interval.alert.manager.publish = 30000
#lenses.interval.topic.earliest.offset = 300000
#lenses.interval.topic.offset.timeout = 5000

#lenses.interval.metrics.refresh.zk = 30000
#lenses.interval.metrics.refresh.sr = 30000
#lenses.interval.metrics.refresh.broker = 30000
#lenses.interval.metrics.refresh.alert.manager = 30000
#lenses.interval.metrics.refresh.connect = 30000
#lenses.interval.metrics.refresh.brokers.in.zk = 10000
#lenses.interval.sql.udf=10000

## Lenses Web Socket API

#lenses.kafka.ws.poll.ms = 1000
#lenses.kafka.ws.buffer.size = 10000
#lenses.kafka.ws.max.poll.records = 1000
#lenses.kafka.ws.heartbeat.ms = 30000

## CORS

#lenses.access.control.allow.methods = "GET,POST,PUT,DELETE,OPTIONS"
#lenses.access.control.allow.origin = "*"

## Whether to allow self-signed certificates and telemetry

#lenses.allow.weak.ssl = false
#lenses.telemetry.enable = true

## Tweak Akka

#lenses.akka.request.timeout.ms = 10000

## List of topics Lenses should treat as `system topics`

#lenses.kafka.control.topics = [
#     "connect-configs",
#     "connect-offsets",
#     "connect-status",
#     "connect-statuses",
#     "_schemas",
#     "__consumer_offsets",
#     "_kafka_lenses_",
#     "lsql_",
#     "lsql-",
#     "__transaction_state"
#   ]

## Alerts bugger
#lenses.alert.buffer.size = 100

## UI settings
## The default records limit for the Kafka topics screen
#lenses.ui.topics.row.limit = 200